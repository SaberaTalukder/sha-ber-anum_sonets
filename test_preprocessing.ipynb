{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations_sonnets(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line.split()) == 1:\n",
    "            if len(obs_elem) > 0:\n",
    "                obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "        else:\n",
    "            line = str(line)\n",
    "            line = re.findall(r\"[\\w'^-]+|[.,!?;]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "            for word in line:\n",
    "                word = re.sub(\"'\", '', word)\n",
    "                word = word.lower()\n",
    "                if word not in obs_map:\n",
    "                    # Add unique words to the observations map.\n",
    "                    obs_map[word] = obs_counter\n",
    "                    obs_counter += 1\n",
    "\n",
    "                # Add the encoded word.\n",
    "                obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations_stanza(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for ln, line in enumerate(lines):\n",
    "        if ln % 14 == 0:\n",
    "            if len(obs_elem) > 0:\n",
    "                obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "            \n",
    "        line = str(line)\n",
    "        line = re.findall(r\"[\\w'^]+|[.,!?;-]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(\"'\", '', word)\n",
    "            word = word.lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations_poem(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for ln, line in enumerate(lines):            \n",
    "        line = str(line)\n",
    "        line = re.findall(r\"[\\w'^]+|[.,!?;-]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(\"'\", '', word)\n",
    "            word = word.lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations(sonnets, sonnets2=\"\", poem3=\"\", poem4=\"\"):\n",
    "    obs, obs_map = parse_observations_sonnets(sonnets, [], {})\n",
    "    obs, obs_map = parse_observations_sonnets(sonnets2, obs, obs_map)\n",
    "    obs, obs_map = parse_observations_stanza(poem3, obs, obs_map)\n",
    "    obs, obs_map = parse_observations_stanza(poem4, obs, obs_map)\n",
    "    return obs, obs_map\n",
    "\n",
    "def print_words(obs, obs_map):\n",
    "    val_map = dict([(value, key) for key, value in obs_map.items()]) \n",
    "    for el in obs:\n",
    "        print(val_map[el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"   1\\n Sharon is talking to Sabera.\\n George is not here yet and we aren't going to start. 'Tis a fun day--hey!\\n\\n Hello, world!\\n      2   \\nThis is a happy-dance. I love you!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sharon': 0,\n",
       " 'is': 1,\n",
       " 'talking': 2,\n",
       " 'to': 3,\n",
       " 'sabera': 4,\n",
       " '.': 5,\n",
       " 'george': 6,\n",
       " 'not': 7,\n",
       " 'here': 8,\n",
       " 'yet': 9,\n",
       " 'and': 10,\n",
       " 'we': 11,\n",
       " 'aren^t': 12,\n",
       " 'going': 13,\n",
       " 'start': 14,\n",
       " '^tis': 15,\n",
       " 'a': 16,\n",
       " 'fun': 17,\n",
       " 'day--hey': 18,\n",
       " '!': 19,\n",
       " 'hello': 20,\n",
       " ',': 21,\n",
       " 'world': 22,\n",
       " 'this': 23,\n",
       " 'happy-dance': 24,\n",
       " 'i': 25,\n",
       " 'love': 26,\n",
       " 'you': 27}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, obs_map = parse_observations(text)\n",
    "obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  3,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  19],\n",
       " [23, 1, 16, 24, 5, 25, 26, 27, 19, 19, 19],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  3,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  19],\n",
       " [23, 1, 16, 24, 5, 25, 26, 27, 19, 19, 19]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map = parse_observations_sonnets(text, [], {})\n",
    "print(len(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "24\n",
      "133\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "sonnets2 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "obs2, obs_map2 = parse_observations_sonnets(sonnets2, [], {})\n",
    "print(len(obs2))\n",
    "poem3 = open(os.path.join(os.getcwd(), 'data/poem3.txt')).read()\n",
    "obs3, obs_map3 = parse_observations_stanza(poem3, [], {})\n",
    "print(len(obs3))\n",
    "poem4 = open(os.path.join(os.getcwd(), 'data/poem4.txt')).read()\n",
    "obs4, obs_map4 = parse_observations_stanza(poem4, [], {})\n",
    "print(len(obs4))\n",
    "print(len(obs) + len(obs2) + len(obs3) + len(obs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "sonnets2 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "poem3 = open(os.path.join(os.getcwd(), 'data/poem3.txt')).read()\n",
    "poem4 = open(os.path.join(os.getcwd(), 'data/poem4.txt')).read()\n",
    "obs_final, obs_map_final = parse_observations(sonnets, sonnets2, poem3, poem4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "fairest\n",
      "creatures\n",
      "we\n",
      "desire\n",
      "increase\n",
      ",\n",
      "that\n",
      "thereby\n",
      "beauty^s\n",
      "rose\n",
      "might\n",
      "never\n",
      "die\n",
      ",\n",
      "but\n",
      "as\n",
      "the\n",
      "riper\n",
      "should\n",
      "by\n",
      "time\n",
      "decease\n",
      ",\n",
      "his\n",
      "tender\n",
      "heir\n",
      "might\n",
      "bear\n",
      "his\n",
      "memory\n",
      "but\n",
      "thou\n",
      "contracted\n",
      "to\n",
      "thine\n",
      "own\n",
      "bright\n",
      "eyes\n",
      ",\n",
      "feed^st\n",
      "thy\n",
      "light^s\n",
      "flame\n",
      "with\n",
      "self-substantial\n",
      "fuel\n",
      ",\n",
      "making\n",
      "a\n",
      "famine\n",
      "where\n",
      "abundance\n",
      "lies\n",
      ",\n",
      "thy\n",
      "self\n",
      "thy\n",
      "foe\n",
      ",\n",
      "to\n",
      "thy\n",
      "sweet\n",
      "self\n",
      "too\n",
      "cruel\n",
      "thou\n",
      "that\n",
      "art\n",
      "now\n",
      "the\n",
      "world^s\n",
      "fresh\n",
      "ornament\n",
      ",\n",
      "and\n",
      "only\n",
      "herald\n",
      "to\n",
      "the\n",
      "gaudy\n",
      "spring\n",
      ",\n",
      "within\n",
      "thine\n",
      "own\n",
      "bud\n",
      "buriest\n",
      "thy\n",
      "content\n",
      ",\n",
      "and\n",
      "tender\n",
      "churl\n",
      "mak^st\n",
      "waste\n",
      "in\n",
      "niggarding\n",
      "pity\n",
      "the\n",
      "world\n",
      ",\n",
      "or\n",
      "else\n",
      "this\n",
      "glutton\n",
      "be\n",
      ",\n",
      "to\n",
      "eat\n",
      "the\n",
      "world^s\n",
      "due\n",
      ",\n",
      "by\n",
      "the\n",
      "grave\n",
      "and\n",
      "thee\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print_words(obs_final[0], obs_map_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
