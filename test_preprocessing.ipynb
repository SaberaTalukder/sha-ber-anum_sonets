{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations_sonnets(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line.split()) == 1:\n",
    "            if len(obs_elem) > 0:\n",
    "                obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "        else:\n",
    "            line = str(line)\n",
    "            line = re.findall(r\"[\\w'^-]+|[.,!?;]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "            for word in line:\n",
    "                word = re.sub(\"'\", '', word)\n",
    "                word = word.lower()\n",
    "                if word not in obs_map:\n",
    "                    # Add unique words to the observations map.\n",
    "                    obs_map[word] = obs_counter\n",
    "                    obs_counter += 1\n",
    "\n",
    "                # Add the encoded word.\n",
    "                obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations_stanza(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for ln, line in enumerate(lines):\n",
    "        if ln % 14 == 0:\n",
    "            if len(obs_elem) > 0:\n",
    "                obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "            \n",
    "        line = str(line)\n",
    "        line = re.findall(r\"[\\w'^]+|[.,!?;-]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(\"'\", '', word)\n",
    "            word = word.lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations_poem(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for ln, line in enumerate(lines):            \n",
    "        line = str(line)\n",
    "        line = re.findall(r\"[\\w'^]+|[.,!?;-]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(\"'\", '', word)\n",
    "            word = word.lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations_lyrics(text, obs=[], obs_map={}):\n",
    "    # Convert text to dataset.\n",
    "    text = re.sub(r'(?<!\\w)([A-Z])\\.', r'\\1', text) # remove dots in acronyms\n",
    "    lines = [line for line in text.split('\\r\\n')]\n",
    "\n",
    "    obs_counter = len(obs_map)\n",
    "    obs_elem = []\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line.split()) < 1:\n",
    "            if len(obs_elem) > 0:\n",
    "                obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "        else:\n",
    "            line = str(line)\n",
    "#             line = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", line)\n",
    "            line = re.findall(r\"[\\w'^-]+|[.,!?;]\", re.sub(\"'\", '^', line))\n",
    "\n",
    "            for word in line:\n",
    "                word = re.sub(\"'\", '', word)\n",
    "                word = word.lower()\n",
    "                if word not in obs_map:\n",
    "                    # Add unique words to the observations map.\n",
    "                    obs_map[word] = obs_counter\n",
    "                    obs_counter += 1\n",
    "\n",
    "                # Add the encoded word.\n",
    "                obs_elem.append(obs_map[word])\n",
    "        \n",
    "    # Add the encoded sequence.\n",
    "    if len(obs_elem) > 0:\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_observations(sonnets, sonnets2=\"\", poem3=\"\", poem4=\"\", lyrics=\"\"):\n",
    "    obs, obs_map = parse_observations_sonnets(sonnets, [], {})\n",
    "    obs, obs_map = parse_observations_sonnets(sonnets2, obs, obs_map)\n",
    "    obs, obs_map = parse_observations_stanza(poem3, obs, obs_map)\n",
    "    obs, obs_map = parse_observations_stanza(poem4, obs, obs_map)\n",
    "    obs, obs_map = parse_observations_lyrics(lyrics, obs, obs_map)\n",
    "    return obs, obs_map\n",
    "\n",
    "def print_words(obs, obs_map):\n",
    "    val_map = dict([(value, key) for key, value in obs_map.items()]) \n",
    "    for el in obs:\n",
    "        print(val_map[el])\n",
    "        \n",
    "        \n",
    "def backward_obs(obs):\n",
    "    obs_backward = copy.deepcopy(obs)\n",
    "    for o in obs_backward:\n",
    "        o.reverse()\n",
    "    return obs_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"   1\\n Sharon is talking to Sabera.\\n George is not here yet and we aren't going to start. 'Tis a fun day--hey!\\n\\n Hello, world!\\n      2   \\nThis is a happy-dance. I love you!!! [Kanye]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sharon': 0,\n",
       " 'is': 1,\n",
       " 'talking': 2,\n",
       " 'to': 3,\n",
       " 'sabera': 4,\n",
       " '.': 5,\n",
       " 'george': 6,\n",
       " 'not': 7,\n",
       " 'here': 8,\n",
       " 'yet': 9,\n",
       " 'and': 10,\n",
       " 'we': 11,\n",
       " 'aren^t': 12,\n",
       " 'going': 13,\n",
       " 'start': 14,\n",
       " '^tis': 15,\n",
       " 'a': 16,\n",
       " 'fun': 17,\n",
       " 'day--hey': 18,\n",
       " '!': 19,\n",
       " 'hello': 20,\n",
       " ',': 21,\n",
       " 'world': 22,\n",
       " 'this': 23,\n",
       " 'happy-dance': 24,\n",
       " 'i': 25,\n",
       " 'love': 26,\n",
       " 'you': 27,\n",
       " 'kanye': 28}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, obs_map = parse_observations(text)\n",
    "obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  3,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  19],\n",
       " [23, 1, 16, 24, 5, 25, 26, 27, 19, 19, 19],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  3,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  19],\n",
       " [23, 1, 16, 24, 5, 25, 26, 27, 19, 19, 19]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map = parse_observations_sonnets(text, [], {})\n",
    "print(len(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "24\n",
      "133\n",
      "363\n",
      "763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "sonnets2 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "obs2, obs_map2 = parse_observations_sonnets(sonnets2, [], {})\n",
    "print(len(obs2))\n",
    "poem3 = open(os.path.join(os.getcwd(), 'data/poem3.txt')).read()\n",
    "obs3, obs_map3 = parse_observations_stanza(poem3, [], {})\n",
    "print(len(obs3))\n",
    "poem4 = open(os.path.join(os.getcwd(), 'data/poem4.txt')).read()\n",
    "obs4, obs_map4 = parse_observations_stanza(poem4, [], {})\n",
    "print(len(obs4))\n",
    "\n",
    "target_url = \"https://pastebin.com/raw/9S5u08EU\" # Kanye lyrics\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request('GET', target_url)\n",
    "lyrics = response.data.decode('utf-8')\n",
    "obs5, obs_map5 = parse_observations_lyrics(lyrics, [], {})\n",
    "print(len(obs5))\n",
    "\n",
    "print(len(obs) + len(obs2) + len(obs3) + len(obs4) + len(obs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "sonnets = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "sonnets2 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "poem3 = open(os.path.join(os.getcwd(), 'data/poem3.txt')).read()\n",
    "poem4 = open(os.path.join(os.getcwd(), 'data/poem4.txt')).read()\n",
    "\n",
    "target_url = \"https://pastebin.com/raw/9S5u08EU\" # Kanye lyrics\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request('GET', target_url)\n",
    "lyrics = response.data.decode('utf-8')\n",
    "\n",
    "obs_final, obs_map_final = parse_observations(sonnets, sonnets2, poem3, poem4, lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "fairest\n",
      "creatures\n",
      "we\n",
      "desire\n",
      "increase\n",
      ",\n",
      "that\n",
      "thereby\n",
      "beauty^s\n",
      "rose\n",
      "might\n",
      "never\n",
      "die\n",
      ",\n",
      "but\n",
      "as\n",
      "the\n",
      "riper\n",
      "should\n",
      "by\n",
      "time\n",
      "decease\n",
      ",\n",
      "his\n",
      "tender\n",
      "heir\n",
      "might\n",
      "bear\n",
      "his\n",
      "memory\n",
      "but\n",
      "thou\n",
      "contracted\n",
      "to\n",
      "thine\n",
      "own\n",
      "bright\n",
      "eyes\n",
      ",\n",
      "feed^st\n",
      "thy\n",
      "light^s\n",
      "flame\n",
      "with\n",
      "self-substantial\n",
      "fuel\n",
      ",\n",
      "making\n",
      "a\n",
      "famine\n",
      "where\n",
      "abundance\n",
      "lies\n",
      ",\n",
      "thy\n",
      "self\n",
      "thy\n",
      "foe\n",
      ",\n",
      "to\n",
      "thy\n",
      "sweet\n",
      "self\n",
      "too\n",
      "cruel\n",
      "thou\n",
      "that\n",
      "art\n",
      "now\n",
      "the\n",
      "world^s\n",
      "fresh\n",
      "ornament\n",
      ",\n",
      "and\n",
      "only\n",
      "herald\n",
      "to\n",
      "the\n",
      "gaudy\n",
      "spring\n",
      ",\n",
      "within\n",
      "thine\n",
      "own\n",
      "bud\n",
      "buriest\n",
      "thy\n",
      "content\n",
      ",\n",
      "and\n",
      "tender\n",
      "churl\n",
      "mak^st\n",
      "waste\n",
      "in\n",
      "niggarding\n",
      "pity\n",
      "the\n",
      "world\n",
      ",\n",
      "or\n",
      "else\n",
      "this\n",
      "glutton\n",
      "be\n",
      ",\n",
      "to\n",
      "eat\n",
      "the\n",
      "world^s\n",
      "due\n",
      ",\n",
      "by\n",
      "the\n",
      "grave\n",
      "and\n",
      "thee\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print_words(obs_final[0], obs_map_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def rhyme(inp, level):\n",
    "     entries = nltk.corpus.cmudict.entries()\n",
    "     syllables = [(word, syl) for word, syl in entries if word == inp]\n",
    "     rhymes = []\n",
    "     for (word, syllable) in syllables:\n",
    "             rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
    "     return list(rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'climbing', 'diming', 'liming', 'priming', 'rhyming', 'timing'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme('climbing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /Users/sharon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climbing\n",
      "rhyming\n",
      "priming\n",
      "liming\n",
      "priming\n",
      "timing\n",
      "rhyming\n",
      "timing\n",
      "timing\n",
      "rhyming\n",
      "liming\n",
      "rhyming\n",
      "liming\n",
      "timing\n",
      "liming\n",
      "priming\n",
      "timing\n",
      "rhyming\n",
      "liming\n",
      "liming\n",
      "priming\n",
      "rhyming\n",
      "diming\n",
      "diming\n",
      "diming\n",
      "priming\n",
      "timing\n",
      "priming\n",
      "liming\n",
      "diming\n",
      "climbing\n",
      "climbing\n",
      "priming\n",
      "diming\n",
      "rhyming\n",
      "priming\n",
      "climbing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-f9e6f1a42aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhyme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'climbing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-33ade101a6d4>\u001b[0m in \u001b[0;36mrhyme\u001b[0;34m(inp, level)\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mrhymes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m              \u001b[0mrhymes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhymes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-33ade101a6d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mrhymes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m              \u001b[0mrhymes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhymes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m'block reader %s() should return list or tuple.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/cmudict.py\u001b[0m in \u001b[0;36mread_cmudict_block\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Read 100 at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mentries\u001b[0m  \u001b[0;31m# end of file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1227\u001b[0m             \u001b[0mchars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinebuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(random.choice(rhyme('climbing', 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('repackaged', ['R', 'IY1', 'P', 'AE0', 'K', 'IH0', 'JH', 'D'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10 5\n",
      "20 10\n",
      "30 17\n",
      "40 21\n",
      "50 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-a5cc293fc82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhymes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhyme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mrhymes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-33ade101a6d4>\u001b[0m in \u001b[0;36mrhyme\u001b[0;34m(inp, level)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrhyme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmudict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m      \u001b[0msyllables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m      \u001b[0mrhymes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-33ade101a6d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrhyme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmudict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m      \u001b[0msyllables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m      \u001b[0mrhymes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    310\u001b[0m             )\n\u001b[1;32m    311\u001b[0m             \u001b[0mnum_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mnew_filepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             assert new_filepos > filepos, (\n\u001b[1;32m    314\u001b[0m                 \u001b[0;34m'block reader %s() should consume at least 1 byte (filepos=%d)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mbuf_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinebuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         est_bytes = int(\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mbytes_read\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_numchars\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_numchars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m         )\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rhymes = 0\n",
    "for i, o in enumerate(obs_map):\n",
    "    if i % 10 == 0:\n",
    "        print(i, rhymes)\n",
    "    if len(rhyme(o, 4)) > 2:\n",
    "        rhymes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"hmm7_kanye.pickle\", \"rb\") as input_file:\n",
    "    hmm7_kanye = pickle.load(input_file)\n",
    "with open(r\"obs_kanye.pickle\", \"rb\") as input_file:\n",
    "    obs_kanye = pickle.load(input_file)\n",
    "with open(r\"obs_map_kanye.pickle\", \"rb\") as input_file:\n",
    "    obs_map_kanye = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 11228)\n",
      "Their time^s my with heaven dying the thy on that him a my a no their her...\n",
      "(7, 11228)\n",
      "Mild flow back age day ritter sex by better bitch general looks 9 drawers fake-ass same...\n",
      "(7, 11228)\n",
      "Me his more this break the a the so my my lovers^ gettin^ the it my...\n",
      "(7, 11228)\n",
      "Bring with excuse warns for with , on with of with without of for ^bout in...\n",
      "(7, 11228)\n",
      "Surviving same sprite milf endowed grutman reproach time awesome remover rreeal society shame mics cream lost...\n",
      "(7, 11228)\n",
      "You she ^em every to niggas super th^ i colour she thou it^s folks you flickin^...\n",
      "(7, 11228)\n",
      "Dreamin^ got most been look divide got went suppose crack surcease cameras paid behold now hit don^t died...\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import timeit\n",
    "import urllib3\n",
    "from HMM_george import unsupervised_HMM\n",
    "from HMM_helper_processed import (\n",
    "    text_to_wordcloud,\n",
    "    states_to_wordclouds,\n",
    "    parse_observations,\n",
    "    sample_sentence,\n",
    "    visualize_sparsities,\n",
    "    animate_emission\n",
    ")\n",
    "import HMM_george\n",
    "importlib.reload(HMM_george)\n",
    "import HMM_helper_processed\n",
    "importlib.reload(HMM_helper_processed)\n",
    "arrangement_of_words2 = [9+8, 8+8, 8+8, 8+8, 8+8, 8+8, 9+9]\n",
    "\n",
    "for num_words in arrangement_of_words2:\n",
    "    sentence = sample_sentence(hmm7_kanye, obs_map_kanye, n_words=num_words)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3], [5, 6, 7, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [5, 6, 7, 8]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "b = copy.deepcopy(a)\n",
    "for e in b:\n",
    "    e.reverse()\n",
    "return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 1], [8, 7, 6, 5]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 6,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 6,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 11,\n",
       " 25,\n",
       " 22,\n",
       " 26,\n",
       " 14,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 6,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 6,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 6,\n",
       " 35,\n",
       " 47,\n",
       " 35,\n",
       " 48,\n",
       " 6,\n",
       " 29,\n",
       " 35,\n",
       " 49,\n",
       " 47,\n",
       " 50,\n",
       " 51,\n",
       " 27,\n",
       " 7,\n",
       " 52,\n",
       " 53,\n",
       " 16,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 6,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 29,\n",
       " 16,\n",
       " 60,\n",
       " 61,\n",
       " 6,\n",
       " 62,\n",
       " 30,\n",
       " 31,\n",
       " 63,\n",
       " 64,\n",
       " 35,\n",
       " 65,\n",
       " 6,\n",
       " 57,\n",
       " 23,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 16,\n",
       " 72,\n",
       " 6,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 6,\n",
       " 29,\n",
       " 78,\n",
       " 16,\n",
       " 54,\n",
       " 79,\n",
       " 6,\n",
       " 19,\n",
       " 16,\n",
       " 80,\n",
       " 57,\n",
       " 81,\n",
       " 82]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
